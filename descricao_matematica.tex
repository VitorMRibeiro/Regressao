\documentclass{article}

\usepackage{amsmath}

\begin{document}

Notação

Negrito = vetor.

Exemplos:

\(\textbf{x}\) é um vetor \([x_0,...,x_n]\)

\(\boldsymbol{\phi}(x)\) é um vetor de funções \([\phi_0(x),...,\phi_n(x)]\)

\section{Regressão}

O objetivo da regressão é fazer previsões dos valores de uma \emph{target variable} \(t\) dado o valor de uma \emph{input variable} \(\bf x\),
\(\bf x\) é um vetor de dimensão qualquer.

Dado um conjunto de dados composto de observações \( \{ \textbf{x}_n \} \) e suas respectivas
\emph{target variables} \( \{t_n\} \), o que se quer fazer é a previsão do valor de \(t\)
dado um valor de \(\bf x\) que não necessariamente está presente nas observações. Em outras palavras,
quer-se encontrar uma função \( y(\textbf{x}) \) que associa cada valor possível de \(\bf x\) a uma previsão de
\(t\).

A função \( y(\textbf{x}) \) pode ser encontrada através do ajuste de parâmetros de uma função 
\( y(\textbf{x}, \textbf{w}) \), onde \( \textbf{w} \) é um vetor de parâmetros ajustáveis. Os valores
finais dos parâmetros ajustáveis \( \textbf{w}_f \) devem ser escolhidos de maneira a minimizar
(ou quase isso) o valor de \( \mathcal{L}(\textbf{w}) \), onde \( \mathcal{L} \) é uma função de perda
adequada. A função de perda \( \mathcal{L} \) é o criterio pelo qual se julga o quão adequadas são as
previsões de \( y(\textbf{x}) = y(\textbf{x}, \textbf{w}_f) \) dado o conjunto de dados.

O método pelo qual os parâmetros ajustáveis são atualizados aqui é o da \emph{descida de gradiente}, onde os parâmetros
são modificados de maneira iterativa na direção do negativo do gradiente da função de perda,
\[ \textbf{w}_{n + 1} = \textbf{w}_n - \lambda \nabla \mathcal{L}(\textbf{w}) \]
ou seja, a cada passo os parâmetros ajustáveis \( \textbf{w} \) são modificados de maneira a diminuir o valor da
função de perda \( \mathcal{L}(\textbf{w}) \).

\section{Modelos Lineares de Regressão}

Os modelos lineares de regressão são aqueles cuja função \( y(\textbf{x}, \textbf{w}) \) é linear em relação aos parâmetros
ajustáveis \( \textbf{w} \), o que não quer dizer que \( y(\textbf{x}, \textbf{w}) \) seja necessariamente linear com relação
à \( \textbf{x} \). No geral, \( y(\textbf{x}, \textbf{w}) \) é uma combinação linear de \emph{basis functions}
\( \phi(\textbf{x}) \), funções de \( \textbf{x} \) que podem ou não ser lineares,
\[ y(\textbf{x}, \textbf{w}) = w_0 + \sum_{i=1}^{M-1} w_i \phi_i(\textbf{x}_n) \]
onde M é a quantidade de parâmetros ajustáveis. A equação anterior pode ser simplificada para \( \textbf{w}^T \boldsymbol{\phi}(\textbf{x}) \)
usando notação vetorial, assumindo que \( \phi_0 = 1 \).

A função de perda utilizada aqui é a soma dos quadrados dos erros, isto é, as diferenças entre as previsões do modelo e o
valor real das observações \( t_n - y(\textbf{x}_n, \textbf{w}) \) são elevadas ao quadrado e somadas, por todas as instâncias
de observação, para gerar um valor que representa o quão adequada é a escolha de valores para \(\textbf{w}\).
\[ \mathcal{L}(\textbf{w}) = 1/2 \sum_{n=1}^{N} \{ t_n - y(\textbf{x}_n, \textbf{w})\}^2 \]
onde \(N\) é a quantidade de observações. Tal escolha de função de perda é justificada se assumirmos que os dados observados
são gerados a partir de uma função determinística somada a um ruído gaussiano.

Essa escolha de função de perda, combinada ao fato de \( y(\textbf{x}, \textbf{w}) = \textbf{w}^T \boldsymbol{\phi}(\textbf{x}) \) ser linear
em relação à \( \textbf{w} \), nos leva à sequinte equação para o gradiente da função de perda
\[ \nabla \mathcal{L}(\textbf{w}) = \sum_{n=1}^{N} \{ t_n - \textbf{w}^T \boldsymbol{\phi}(\textbf{x}_n) \} \boldsymbol{\phi}(\textbf{x}_n)^T \].

\section{Referências}

\emph{Pattern Recognition and Machine Learning - Christopher Bishop, Capítulo 3.}
\end{document}